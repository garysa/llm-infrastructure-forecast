<h1 id="llm-infrastructure-forecast">LLM Infrastructure Forecast</h1>
<h2 id="what-is-a-tpu">1. What is a TPU?</h2>
<p>A <strong>TPU (Tensor Processing Unit)</strong> is a custom-designed
AI accelerator chip developed by Google specifically for machine
learning workloads.</p>
<h3 id="key-characteristics">Key Characteristics</h3>
<ul>
<li><strong>Purpose-built for ML</strong>: Optimized for matrix
operations and tensor computations common in neural networks</li>
<li><strong>High throughput</strong>: Excels at large-scale,
low-precision (8-bit) matrix multiplications</li>
<li><strong>Architecture</strong>: Uses a systolic array design that
efficiently moves data through processing elements</li>
<li><strong>Power efficient</strong>: Delivers more ML performance per
watt compared to general-purpose GPUs/CPUs</li>
</ul>
<h3 id="tpu-vs-gpu">TPU vs GPU</h3>
<table>
<colgroup>
<col style="width: 44%" />
<col style="width: 27%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>TPU</th>
<th>GPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Specialization</td>
<td>ML-only</td>
<td>General-purpose parallel computing</td>
</tr>
<tr class="even">
<td>Best for</td>
<td>Large transformers, inference at scale</td>
<td>Varied workloads, smaller models</td>
</tr>
<tr class="odd">
<td>Flexibility</td>
<td>Limited</td>
<td>High</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="will-asics-dominate-if-llms-become-mainstream">2. Will ASICs
Dominate if LLMs Become Mainstream?</h2>
<h3 id="arguments-for-asic-dominance">Arguments For ASIC Dominance</h3>
<ul>
<li><strong>Efficiency</strong>: ASICs can be 10-100x more
power-efficient than GPUs for specific workloads</li>
<li><strong>Cost at scale</strong>: Once designed, per-unit costs drop
significantly in high volume</li>
<li><strong>Inference dominance</strong>: If LLMs become ubiquitous,
inference will be the bulk of compute—ideal for ASICs</li>
<li><strong>Edge deployment</strong>: Running models on phones/devices
almost certainly requires custom silicon</li>
</ul>
<h3 id="arguments-against-gpu-resilience">Arguments Against (GPU
Resilience)</h3>
<ul>
<li><strong>Rapid model evolution</strong>: LLM architectures are still
changing fast (attention variants, MoE, SSMs like Mamba). ASICs take 2-3
years to design—risky if architectures shift</li>
<li><strong>NVIDIA’s moat</strong>: CUDA ecosystem, software stack, and
developer familiarity are deeply entrenched</li>
<li><strong>Flexibility</strong>: GPUs can run any model; ASICs may
become obsolete if paradigms change</li>
<li><strong>Hybrid approaches</strong>: NVIDIA is increasingly adding
specialized tensor cores—blurring the line</li>
</ul>
<h3 id="current-trajectory">Current Trajectory</h3>
<ul>
<li>Hyperscalers (Google, Amazon, Microsoft) are building custom chips
(TPU, Trainium, Maia)</li>
<li>Startups (Groq, Cerebras, SambaNova) are betting on specialized
architectures</li>
<li>NVIDIA still dominates (~80%+ of AI training market)</li>
</ul>
<h3 id="likely-outcome">Likely Outcome</h3>
<p>A mixed ecosystem—ASICs for inference at scale and edge, GPUs for
training and flexibility. If architectures stabilize, ASICs gain ground.
If innovation continues rapidly, GPUs remain essential.</p>
<hr />
<h2 id="enterprise-llm-deployment-hybrid-model">3. Enterprise LLM
Deployment: Hybrid Model</h2>
<p>The likely future is a <strong>hybrid model</strong> where companies
run private small LLMs for routine tasks and use public cloud LLMs for
heavy compute. This mirrors how companies handle compute generally
(on-prem + cloud).</p>
<h3 id="why-private-small-llms-make-sense">Why Private Small LLMs Make
Sense</h3>
<ul>
<li><strong>Data privacy</strong>: Sensitive data (legal, medical,
financial, IP) never leaves the network</li>
<li><strong>Latency</strong>: Local inference is faster for real-time
applications</li>
<li><strong>Cost predictability</strong>: Fixed infrastructure
vs. per-token API costs that can spike</li>
<li><strong>Customization</strong>: Fine-tuned on proprietary data,
jargon, workflows</li>
<li><strong>Compliance</strong>: Easier to meet regulatory requirements
(GDPR, HIPAA, etc.)</li>
</ul>
<h3 id="why-public-llms-for-heavy-compute">Why Public LLMs for Heavy
Compute</h3>
<ul>
<li><strong>Frontier capabilities</strong>: Largest models require
massive infrastructure</li>
<li><strong>Occasional use</strong>: Doesn’t justify owning the
hardware</li>
<li><strong>Rapid improvement</strong>: API access means instant
upgrades without redeployment</li>
<li><strong>Burst capacity</strong>: Handle spikes without
over-provisioning</li>
</ul>
<h3 id="emerging-deployment-patterns">Emerging Deployment Patterns</h3>
<table>
<thead>
<tr class="header">
<th>Use Case</th>
<th>Likely Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Internal chatbots, code assist</td>
<td>Private small LLM (7B-70B)</td>
</tr>
<tr class="even">
<td>Document search/RAG</td>
<td>Private, fine-tuned</td>
</tr>
<tr class="odd">
<td>Complex reasoning, research</td>
<td>Public frontier API</td>
</tr>
<tr class="even">
<td>Customer-facing products</td>
<td>Hybrid or public</td>
</tr>
<tr class="odd">
<td>Edge/embedded</td>
<td>Tiny private models (&lt;3B)</td>
</tr>
</tbody>
</table>
<h3 id="the-analogy">The Analogy</h3>
<p>It’s like databases—companies run private databases for core
operations but use cloud services for analytics, burst workloads, or
specialized capabilities.</p>
<hr />
<h2 id="the-bitcoin-asic-analogy-will-history-repeat">4. The Bitcoin
ASIC Analogy: Will History Repeat?</h2>
<p>Bitcoin mining evolved from CPUs → GPUs → FPGAs → ASICs, with ASICs
now dominating completely. Will LLM inference follow the same path?</p>
<h3 id="why-bitcoin-asics-dominated-completely">Why Bitcoin ASICs
Dominated Completely</h3>
<ul>
<li><strong>Single, fixed algorithm</strong>: SHA-256 never changes</li>
<li><strong>Pure economics</strong>: Only metric is hashes per watt per
dollar</li>
<li><strong>No flexibility needed</strong>: The workload is 100%
predictable forever</li>
<li><strong>Winner-take-all</strong>: Efficiency directly equals
profit</li>
</ul>
<h3 id="why-llm-asics-wont-dominate-as-completely">Why LLM ASICs Won’t
Dominate as Completely</h3>
<table>
<colgroup>
<col style="width: 34%" />
<col style="width: 39%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="header">
<th>Factor</th>
<th>Bitcoin</th>
<th>LLMs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Algorithm stability</td>
<td>Fixed forever</td>
<td>Evolving (attention → MoE → SSM?)</td>
</tr>
<tr class="even">
<td>Workload variety</td>
<td>One operation</td>
<td>Many (different models, quantizations, batch sizes)</td>
</tr>
<tr class="odd">
<td>Market maturity</td>
<td>15+ years</td>
<td>~3 years</td>
</tr>
<tr class="even">
<td>Upgrade cycle</td>
<td>Rare algorithm changes</td>
<td>New architectures yearly</td>
</tr>
</tbody>
</table>
<h3 id="where-llm-asics-will-likely-dominate">Where LLM ASICs Will
Likely Dominate</h3>
<ul>
<li><strong>Edge devices</strong> (phones, cars, IoT): ASICs will
dominate—battery life is critical</li>
<li><strong>High-volume inference</strong>: Running the same 7B model
billions of times justifies custom silicon</li>
<li><strong>Commoditized models</strong>: Once a model becomes “good
enough” and stable (like Llama-class), ASICs become viable</li>
</ul>
<h3 id="likely-pattern-by-use-case">Likely Pattern by Use Case</h3>
<table>
<thead>
<tr class="header">
<th>Use Case</th>
<th>Dominant Hardware</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training</td>
<td>GPUs (too dynamic)</td>
</tr>
<tr class="even">
<td>Large inference (cloud)</td>
<td>Mix of GPUs + specialized accelerators</td>
</tr>
<tr class="odd">
<td>Small inference (edge)</td>
<td>ASICs (similar to Bitcoin)</td>
</tr>
</tbody>
</table>
<h3 id="the-key-variable">The Key Variable</h3>
<p>Architecture stability determines ASIC viability. If transformers
remain the standard for 5+ years, ASICs will take over inference. If
major shifts occur (like Mamba/SSMs gaining traction), GPU flexibility
remains valuable.</p>
<hr />
<h2
id="the-fragmented-agi-future-data-sovereignty-forces-decentralization">5.
The Fragmented AGI Future: Data Sovereignty Forces Decentralization</h2>
<p>The current centralized API model (everyone sends data to
OpenAI/Anthropic/Google) is unlikely to survive the path to AGI. Data
security requirements in a capitalist model will force
fragmentation.</p>
<h3 id="why-centralized-apis-wont-scale-to-agi">Why Centralized APIs
Won’t Scale to AGI</h3>
<ul>
<li><strong>Data is the moat</strong>: Corporations won’t send
proprietary data to potential competitors</li>
<li><strong>Regulatory pressure</strong>: GDPR, HIPAA, national security
laws prohibit cross-border data flows</li>
<li><strong>Competitive risk</strong>: Training data leakage could
destroy competitive advantage</li>
<li><strong>National security</strong>: Governments won’t route
sensitive queries through foreign systems</li>
</ul>
<h3 id="the-emerging-tiered-model">The Emerging Tiered Model</h3>
<figure>
<img src="agi_future_tiers.png" alt="AGI Future Tiers" />
<figcaption aria-hidden="true">AGI Future Tiers</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 18%" />
<col style="width: 31%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr class="header">
<th>Tier</th>
<th>Users</th>
<th>Model Type</th>
<th>Data Policy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Tier 1: Public/Open</strong></td>
<td>Education, researchers, general public</td>
<td>Open source (Llama, Mistral)</td>
<td>Public data only</td>
</tr>
<tr class="even">
<td><strong>Tier 2: Enterprise</strong></td>
<td>Corporations</td>
<td>Private fine-tuned, on-prem</td>
<td>Data stays internal</td>
</tr>
<tr class="odd">
<td><strong>Tier 3: Regulated</strong></td>
<td>Healthcare, finance, legal</td>
<td>Certified &amp; audited</td>
<td>Compliance-first</td>
</tr>
<tr class="even">
<td><strong>Tier 4: Sovereign</strong></td>
<td>Governments, defense, intelligence</td>
<td>Air-gapped, national</td>
<td>Complete isolation</td>
</tr>
</tbody>
</table>
<h3 id="market-projection">Market Projection</h3>
<figure>
<img src="agi_market_projection.png" alt="Market Projection" />
<figcaption aria-hidden="true">Market Projection</figcaption>
</figure>
<p>The centralized API model (currently ~85% of AI compute market) will
decline to ~10% by 2032 as: - Enterprise moves compute on-premises -
Governments mandate sovereign AI capabilities - Open models become
capable enough for public use</p>
<h3 id="the-google-analogy">The Google Analogy</h3>
<p>Just as Google Search is “free” for public use while enterprises pay
for private search appliances and governments build classified systems,
AGI will fragment into:</p>
<ul>
<li><strong>Public AGI</strong>: Ad-supported or government-subsidized
for education/general use</li>
<li><strong>Enterprise AGI</strong>: Licensed, on-prem, fine-tuned on
proprietary data</li>
<li><strong>Sovereign AGI</strong>: National AI capabilities, completely
isolated</li>
</ul>
<h3 id="implications">Implications</h3>
<ol type="1">
<li><strong>No single AGI monopoly</strong>: Unlike search (Google
dominance), AGI will be fragmented by design</li>
<li><strong>NVIDIA benefits</strong>: Sells hardware to all tiers, not
dependent on any single provider</li>
<li><strong>Open source critical</strong>: Public tier depends on open
models (Llama successors)</li>
<li><strong>Talent fragmentation</strong>: AI researchers spread across
government, enterprise, public sectors</li>
</ol>
<hr />
<h2 id="the-power-bottleneck-does-china-win-the-7-year-race">6. The
Power Bottleneck: Does China Win the 7-Year Race?</h2>
<p>If power becomes the primary constraint on AI scaling, geopolitical
dynamics shift dramatically. China’s infrastructure advantages could
prove decisive.</p>
<h3 id="the-power-problem">The Power Problem</h3>
<ul>
<li><strong>Current AI data center</strong>: 50-100 MW typical</li>
<li><strong>Next-gen training clusters</strong>: 500 MW - 1 GW
required</li>
<li><strong>GPT-5 class training run</strong>: Estimated 100+ MW
sustained for months</li>
<li><strong>AGI-scale compute</strong>: Potentially 5-10 GW dedicated
facilities</li>
</ul>
<p>For context: 1 GW = roughly one nuclear reactor’s output</p>
<h3 id="why-power-is-the-bottleneck">Why Power is the Bottleneck</h3>
<table>
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="header">
<th>Constraint</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Grid capacity</td>
<td>Most grids can’t deliver GW-scale to single sites</td>
</tr>
<tr class="even">
<td>Permitting</td>
<td>New power plants take 5-10 years in the West</td>
</tr>
<tr class="odd">
<td>Transmission</td>
<td>Building new high-voltage lines faces NIMBY resistance</td>
</tr>
<tr class="even">
<td>Renewable intermittency</td>
<td>AI training needs 24/7 baseload, not variable solar/wind</td>
</tr>
</tbody>
</table>
<h3 id="chinas-structural-advantages">China’s Structural Advantages</h3>
<table>
<thead>
<tr class="header">
<th>Factor</th>
<th>China</th>
<th>US/West</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Permitting speed</td>
<td>Months</td>
<td>5-10 years</td>
</tr>
<tr class="even">
<td>State coordination</td>
<td>Central planning</td>
<td>Fragmented jurisdictions</td>
</tr>
<tr class="odd">
<td>Grid buildout</td>
<td>Rapid expansion</td>
<td>Aging infrastructure</td>
</tr>
<tr class="even">
<td>Nuclear expansion</td>
<td>150+ reactors planned</td>
<td>Regulatory paralysis</td>
</tr>
<tr class="odd">
<td>Coal availability</td>
<td>Abundant (less clean)</td>
<td>Politically constrained</td>
</tr>
<tr class="even">
<td>Land acquisition</td>
<td>State-controlled</td>
<td>Private property rights</td>
</tr>
</tbody>
</table>
<h3 id="year-evolution-scenario-2026-2033">7-Year Evolution Scenario
(2026-2033)</h3>
<p><strong>Year 1-2 (2026-2027):</strong> - US leads on model
architecture and software - Power constraints begin limiting US scaling
- China breaks ground on dedicated AI power plants</p>
<p><strong>Year 3-4 (2028-2029):</strong> - US data centers hitting grid
limits - China’s new nuclear/coal plants coming online - Compute parity
approaches despite US chip lead</p>
<p><strong>Year 5-7 (2030-2033):</strong> - China achieves raw compute
advantage through power availability - US forced into efficiency-focused
approach - Winner determined by whether algorithms or compute matter
more</p>
<h3 id="the-critical-question">The Critical Question</h3>
<p><strong>If scaling laws hold</strong> (more compute = better AI):
China wins through brute force power advantage</p>
<p><strong>If algorithmic breakthroughs dominate</strong>: US/West wins
through talent and research ecosystem</p>
<h3 id="counterarguments-why-us-could-still-win">Counterarguments (Why
US Could Still Win)</h3>
<ul>
<li><strong>Chip restrictions</strong>: China still behind on
cutting-edge chips (NVIDIA H100/B100 banned)</li>
<li><strong>Talent</strong>: Top AI researchers still concentrated in
US</li>
<li><strong>Efficiency gains</strong>: US forced to innovate on
efficiency (smaller, better models)</li>
<li><strong>Allies</strong>: Japan, Taiwan, Korea, EU add to Western
compute pool</li>
<li><strong>Private capital</strong>: US tech giants can outspend
Chinese state in some scenarios</li>
</ul>
<h3 id="likely-outcome-1">Likely Outcome</h3>
<p>A bifurcated AI world by 2033: - <strong>Chinese AI sphere</strong>:
Raw power advantage, state-controlled, closed ecosystem -
<strong>Western AI sphere</strong>: Efficiency-focused, distributed,
allied nations pooling resources</p>
<p>Neither achieves global AGI monopoly. The “winner” depends on which
approach proves more effective—and we won’t know until it happens.</p>
<hr />
<h2 id="what-if-agi-doesnt-scale-the-moores-law-parallel">7. What If AGI
Doesn’t Scale? The Moore’s Law Parallel</h2>
<p>The assumption that “more compute = smarter AI” may break down, just
as Moore’s Law eventually hit physical limits. This section models
scenarios where scaling fails.</p>
<h3 id="the-moores-law-template">The Moore’s Law Template</h3>
<figure>
<img src="scaling_limits.png" alt="Scaling Limits" />
<figcaption aria-hidden="true">Scaling Limits</figcaption>
</figure>
<p>Moore’s Law history shows a pattern that AI may follow: -
<strong>1970-2010</strong>: Exponential scaling held (transistors
doubled every 2 years) - <strong>2010-2025</strong>: Dennard scaling
ended; gains slowed to ~3 year doubling - <strong>2025+</strong>:
Physical limits (atomic scale) cause further slowdown</p>
<h3 id="ai-scaling-current-state">AI Scaling: Current State</h3>
<table>
<thead>
<tr class="header">
<th>Year</th>
<th>Model</th>
<th>Capability Leap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2017</td>
<td>Transformer</td>
<td>Architecture breakthrough</td>
</tr>
<tr class="even">
<td>2020</td>
<td>GPT-3</td>
<td>Scale breakthrough (175B params)</td>
</tr>
<tr class="odd">
<td>2023</td>
<td>GPT-4</td>
<td>Multimodal + reasoning</td>
</tr>
<tr class="even">
<td>2024-26</td>
<td>Current</td>
<td>Incremental gains, diminishing returns visible</td>
</tr>
</tbody>
</table>
<h3 id="four-scenarios-for-2026-2036">Four Scenarios for 2026-2036</h3>
<figure>
<img src="binding_constraints.png" alt="Binding Constraints" />
<figcaption aria-hidden="true">Binding Constraints</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 27%" />
<col style="width: 33%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th>Assumption</th>
<th>2036 Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Optimistic</strong></td>
<td>Scaling continues</td>
<td>AGI achieved</td>
</tr>
<tr class="even">
<td><strong>Moderate</strong></td>
<td>Moore’s Law pattern slowdown</td>
<td>~3x current capability, no AGI</td>
</tr>
<tr class="odd">
<td><strong>Pessimistic</strong></td>
<td>Hard ceiling (data exhaustion)</td>
<td>~1.5x current, plateau</td>
</tr>
<tr class="even">
<td><strong>Plateau</strong></td>
<td>Brief gains then stagnation</td>
<td>Near-current levels, no AGI</td>
</tr>
</tbody>
</table>
<h3 id="the-binding-constraints">The Binding Constraints</h3>
<p>Multiple factors could independently halt progress:</p>
<ol type="1">
<li><strong>Training Data Exhaustion</strong>
<ul>
<li>Internet-scale text already consumed</li>
<li>Synthetic data has diminishing returns</li>
<li>Human-generated content growth is linear, not exponential</li>
</ul></li>
<li><strong>Compute Limits</strong>
<ul>
<li>Power constraints (see Section 6)</li>
<li>Chip fabrication limits</li>
<li>Cost becomes prohibitive</li>
</ul></li>
<li><strong>Algorithmic Ceiling</strong>
<ul>
<li>Transformer architecture may be near-optimal for current
approach</li>
<li>No obvious successor paradigm</li>
<li>Fundamental limits on what pattern matching can achieve</li>
</ul></li>
<li><strong>Energy/Power Wall</strong>
<ul>
<li>Training runs already consuming city-scale power</li>
<li>Cannot scale 100x without new power infrastructure</li>
</ul></li>
</ol>
<h3 id="the-critical-insight">The Critical Insight</h3>
<p><strong>Capability = Minimum(Compute, Data, Algorithms,
Energy)</strong></p>
<p>Progress stops when ANY constraint binds. Even if compute scales,
data exhaustion or algorithmic limits could halt progress.</p>
<h3 id="historical-precedents-for-stalled-scaling">Historical Precedents
for Stalled Scaling</h3>
<table>
<thead>
<tr class="header">
<th>Technology</th>
<th>Scaling Period</th>
<th>What Stopped It</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Moore’s Law</td>
<td>1970-2010</td>
<td>Physics (atomic limits)</td>
</tr>
<tr class="even">
<td>Airplane Speed</td>
<td>1910-1970</td>
<td>Sonic boom, fuel efficiency</td>
</tr>
<tr class="odd">
<td>Nuclear Power</td>
<td>1950-1980</td>
<td>Safety, regulation, economics</td>
</tr>
<tr class="even">
<td>Fusion Power</td>
<td>1960-present</td>
<td>Plasma containment physics</td>
</tr>
</tbody>
</table>
<h3 id="implications-if-scaling-fails">Implications If Scaling
Fails</h3>
<ul>
<li><strong>No AGI by 2036</strong>: Current LLMs represent the
plateau</li>
<li><strong>Efficiency becomes paramount</strong>: Focus shifts to doing
more with less</li>
<li><strong>Specialization wins</strong>: Domain-specific models
outperform general ones</li>
<li><strong>China’s power advantage irrelevant</strong>: If scaling
doesn’t help, brute force fails</li>
<li><strong>Talent matters more</strong>: Algorithmic breakthroughs
become the only path forward</li>
</ul>
<h3 id="the-uncomfortable-question">The Uncomfortable Question</h3>
<p>Current AI progress may be a <strong>one-time windfall</strong> from:
1. Transformer architecture (2017) 2. Scale discovery (2020) 3.
Internet-scale training data (finite resource)</p>
<p>If no new paradigm emerges, we may be witnessing the <strong>peak of
this approach</strong>, not the beginning of exponential takeoff.</p>
<hr />
<h2 id="the-data-wall-how-can-openai-continue-scaling">8. The Data Wall:
How Can OpenAI Continue Scaling?</h2>
<p>The fundamental problem: scaling requires exponentially more data,
but high-quality training data is finite and already exhausted.</p>
<h3 id="the-numbers-dont-work">The Numbers Don’t Work</h3>
<figure>
<img src="data_wall.png" alt="Data Wall" />
<figcaption aria-hidden="true">Data Wall</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Training Tokens</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GPT-2 (2019)</td>
<td>~10 billion</td>
<td>✓ Abundant data</td>
</tr>
<tr class="even">
<td>GPT-3 (2020)</td>
<td>~300 billion</td>
<td>✓ Plenty remaining</td>
</tr>
<tr class="odd">
<td>GPT-4 (2023)</td>
<td>~13 trillion</td>
<td>⚠ Used most of internet</td>
</tr>
<tr class="even">
<td>GPT-5 (2025?)</td>
<td>~50+ trillion</td>
<td>❌ Doesn’t exist</td>
</tr>
<tr class="odd">
<td>GPT-6 (2027?)</td>
<td>~200+ trillion</td>
<td>❌ Impossible</td>
</tr>
</tbody>
</table>
<p><strong>Available high-quality text on the internet: ~10-15 trillion
tokens</strong> <strong>Annual new content creation: ~1-2 trillion
tokens</strong></p>
<h3 id="data-sources-already-exhausted">Data Sources: Already
Exhausted</h3>
<figure>
<img src="data_timeline.png" alt="Data Timeline" />
<figcaption aria-hidden="true">Data Timeline</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th>Source</th>
<th>Size (tokens)</th>
<th>% Already Used</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Common Crawl (web)</td>
<td>~10 trillion</td>
<td>95%</td>
</tr>
<tr class="even">
<td>Books (scanned)</td>
<td>~2 trillion</td>
<td>80%</td>
</tr>
<tr class="odd">
<td>Wikipedia</td>
<td>~100 billion</td>
<td>100%</td>
</tr>
<tr class="even">
<td>GitHub (code)</td>
<td>~1 trillion</td>
<td>90%</td>
</tr>
<tr class="odd">
<td>Scientific papers</td>
<td>~500 billion</td>
<td>70%</td>
</tr>
<tr class="even">
<td>Reddit/Forums</td>
<td>~800 billion</td>
<td>85%</td>
</tr>
</tbody>
</table>
<h3 id="openais-attempted-solutions">OpenAI’s Attempted Solutions</h3>
<h4 id="synthetic-data-generation">1. Synthetic Data Generation</h4>
<ul>
<li>Train AI to generate training data for the next AI</li>
<li><strong>Problem</strong>: Model collapse—quality degrades each
generation</li>
<li>Research shows 50%+ synthetic data causes rapid quality loss</li>
<li>“Eating your own tail” doesn’t add new information</li>
</ul>
<h4 id="licensed-data-deals">2. Licensed Data Deals</h4>
<ul>
<li>Reddit: $60M/year deal</li>
<li>News publishers: Various agreements</li>
<li>Book publishers: Ongoing negotiations</li>
<li><strong>Problem</strong>: Expensive, finite, legally contested</li>
</ul>
<h4 id="multimodal-expansion">3. Multimodal Expansion</h4>
<ul>
<li>Video (YouTube): Massive but different modality</li>
<li>Audio (podcasts): Adds some text equivalent</li>
<li>Images: Doesn’t help text reasoning</li>
<li><strong>Problem</strong>: Not equivalent to text for language
models</li>
</ul>
<h4 id="user-interaction-data">4. User Interaction Data</h4>
<ul>
<li>Billions of ChatGPT conversations</li>
<li><strong>Problem</strong>: Privacy laws, user consent issues, legal
risk</li>
<li>EU likely to prohibit without explicit consent</li>
</ul>
<h4 id="rlhfquality-over-quantity">5. RLHF/Quality Over Quantity</h4>
<ul>
<li>Better curation of existing data</li>
<li>Human feedback improves output quality</li>
<li><strong>Problem</strong>: Doesn’t add new knowledge or
capabilities</li>
</ul>
<h3 id="the-synthetic-data-trap">The Synthetic Data Trap</h3>
<p>When models train on AI-generated content:</p>
<table>
<thead>
<tr class="header">
<th>Generation</th>
<th>Quality</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>100%</td>
<td>Original human data</td>
</tr>
<tr class="even">
<td>2</td>
<td>95%</td>
<td>Slight degradation</td>
</tr>
<tr class="odd">
<td>3</td>
<td>88%</td>
<td>Patterns simplify</td>
</tr>
<tr class="even">
<td>4</td>
<td>78%</td>
<td>Diversity collapses</td>
</tr>
<tr class="odd">
<td>5</td>
<td>65%</td>
<td>Obvious artifacts</td>
</tr>
<tr class="even">
<td>10</td>
<td>&lt;40%</td>
<td>Unusable</td>
</tr>
</tbody>
</table>
<p>This is called <strong>model collapse</strong>—the AI equivalent of
inbreeding.</p>
<h3 id="post-data-wall-strategies-compared">Post-Data-Wall Strategies
Compared</h3>
<table>
<thead>
<tr class="header">
<th>Strategy</th>
<th>Effectiveness</th>
<th>Feasibility</th>
<th>Risk</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>More compute</td>
<td>Low</td>
<td>High</td>
<td>Low</td>
</tr>
<tr class="even">
<td>Synthetic data</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
</tr>
<tr class="odd">
<td>Licensed data</td>
<td>Medium</td>
<td>Medium</td>
<td>Medium</td>
</tr>
<tr class="even">
<td>Multimodal</td>
<td>Medium</td>
<td>Medium</td>
<td>Low</td>
</tr>
<tr class="odd">
<td>RLHF quality</td>
<td>Medium</td>
<td>High</td>
<td>Low</td>
</tr>
<tr class="even">
<td>Algorithmic breakthrough</td>
<td>High</td>
<td>Low</td>
<td>Low</td>
</tr>
</tbody>
</table>
<h3 id="the-uncomfortable-reality">The Uncomfortable Reality</h3>
<p><strong>OpenAI cannot continue the scaling approach</strong> that
made GPT-3→GPT-4 successful. The options are:</p>
<ol type="1">
<li><strong>Admit diminishing returns</strong>: Incremental improvements
only</li>
<li><strong>Pivot to efficiency</strong>: Smaller, better models
(opposite of scaling)</li>
<li><strong>Hope for breakthroughs</strong>: New architectures that need
less data</li>
<li><strong>Synthetic data gamble</strong>: Risk model collapse for
potential gains</li>
</ol>
<h3 id="what-this-means-for-agi">What This Means for AGI</h3>
<p>If data is the bottleneck: - <strong>AGI via scaling is
impossible</strong>: Not enough data exists - <strong>Algorithmic
breakthroughs required</strong>: Fundamentally new approaches -
<strong>China’s compute advantage irrelevant</strong>: Can’t train what
doesn’t exist - <strong>Open source catches up</strong>: Diminishing
returns level the field</p>
<p>The scaling era (2019-2024) may be over. What comes next is
uncertain.</p>
<hr />
<p><em>Generated: February 2026</em></p>
